model:
  name: wan-2.1-1.3b
  base_ckpt: "Wan-AI/Wan2.1-T2V-1.3B-Diffusers"
  lora_path: "outputs/lora_har/lora_ema_last"
  framepack_ckpt: "hunyuanvideo-community/HunyuanVideo"
  framepack_transformer: "lllyasviel/FramePackI2V_HY"
  framepack_flux: "lllyasviel/flux_redux_bfl"     # must match the exact encoder used when training
  framepack_t2i: "black-forest-labs/FLUX.1-dev"   

sampler:
  frames: 32             # increase for longer videos
  fps: 8
  size: 448
  steps: 20
  cfg_scale: 6.0
  seed: 42
  vae_t_chunk: 3         # safe default; lower for limited VRAM
  negative_prompt: ""    # optional
  sampling_type: "inverted_anti_drifting"

dataset:
  classes: ["walking", "running", "jumping", "waving"]
  per_class: 1
  out_dir: "content/WAN-2.1-Working/outputs/samples"
